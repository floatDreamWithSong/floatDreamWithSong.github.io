# GPT的缺陷

## token的限制

普通使用者的误区：认为GPT的token可以分多次对话使用，可以记住我们的历史对话，但是实际上这些数据都存在内存或者数据库，对话时实际是将近几次对话通过prompt拼接在一起，所以token的限制依然存在，当对话数据超过了token的限制，历史就会丢失。

## token过大，响应变慢

## 创新性的东西

### 语义搜索

特定领域的文档转化为向量，存在向量数据库，用户输入问题时，将问题转化成向量，在上下文搜索，找到最相关的文档，再生成回答。

#### 记忆搜索

将提问的向量和以前的向量匹配，找到相近的向量再生成prompt，提高回答质量
