import{_ as t}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,d as o,o as a}from"./app-Cki7O3Rc.js";const r={};function p(h,e){return a(),n("div",null,e[0]||(e[0]=[o('<h1 id="gpt的缺陷" tabindex="-1"><a class="header-anchor" href="#gpt的缺陷"><span>GPT的缺陷</span></a></h1><h2 id="token的限制" tabindex="-1"><a class="header-anchor" href="#token的限制"><span>token的限制</span></a></h2><p>普通使用者的误区：认为GPT的token可以分多次对话使用，可以记住我们的历史对话，但是实际上这些数据都存在内存或者数据库，对话时实际是将近几次对话通过prompt拼接在一起，所以token的限制依然存在，当对话数据超过了token的限制，历史就会丢失。</p><h2 id="token过大-响应变慢" tabindex="-1"><a class="header-anchor" href="#token过大-响应变慢"><span>token过大，响应变慢</span></a></h2><h2 id="创新性的东西" tabindex="-1"><a class="header-anchor" href="#创新性的东西"><span>创新性的东西</span></a></h2><h3 id="语义搜索" tabindex="-1"><a class="header-anchor" href="#语义搜索"><span>语义搜索</span></a></h3><p>特定领域的文档转化为向量，存在向量数据库，用户输入问题时，将问题转化成向量，在上下文搜索，找到最相关的文档，再生成回答。</p><h4 id="记忆搜索" tabindex="-1"><a class="header-anchor" href="#记忆搜索"><span>记忆搜索</span></a></h4><p>将提问的向量和以前的向量匹配，找到相近的向量再生成prompt，提高回答质量</p>',9)]))}const l=t(r,[["render",p],["__file","第十周.html.vue"]]),c=JSON.parse('{"path":"/posts/%E7%A0%94%E7%A9%B6%E7%94%9F%E7%BB%84%E4%BC%9A%E7%BA%AA%E5%BD%95/%E7%AC%AC%E5%8D%81%E5%91%A8.html","title":"GPT的缺陷","lang":"zh-CN","frontmatter":{"description":"GPT的缺陷 token的限制 普通使用者的误区：认为GPT的token可以分多次对话使用，可以记住我们的历史对话，但是实际上这些数据都存在内存或者数据库，对话时实际是将近几次对话通过prompt拼接在一起，所以token的限制依然存在，当对话数据超过了token的限制，历史就会丢失。 token过大，响应变慢 创新性的东西 语义搜索 特定领域的文档转...","gitInclude":[],"head":[["meta",{"property":"og:url","content":"https://mister-hope.github.io/posts/%E7%A0%94%E7%A9%B6%E7%94%9F%E7%BB%84%E4%BC%9A%E7%BA%AA%E5%BD%95/%E7%AC%AC%E5%8D%81%E5%91%A8.html"}],["meta",{"property":"og:site_name","content":"DayDreamer的个人博客"}],["meta",{"property":"og:title","content":"GPT的缺陷"}],["meta",{"property":"og:description","content":"GPT的缺陷 token的限制 普通使用者的误区：认为GPT的token可以分多次对话使用，可以记住我们的历史对话，但是实际上这些数据都存在内存或者数据库，对话时实际是将近几次对话通过prompt拼接在一起，所以token的限制依然存在，当对话数据超过了token的限制，历史就会丢失。 token过大，响应变慢 创新性的东西 语义搜索 特定领域的文档转..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"GPT的缺陷\\",\\"image\\":[\\"\\"],\\"dateModified\\":null,\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"DayDreamer\\",\\"url\\":\\"https://floatDreamWithSong.github.io\\"}]}"]]},"headers":[{"level":2,"title":"token的限制","slug":"token的限制","link":"#token的限制","children":[]},{"level":2,"title":"token过大，响应变慢","slug":"token过大-响应变慢","link":"#token过大-响应变慢","children":[]},{"level":2,"title":"创新性的东西","slug":"创新性的东西","link":"#创新性的东西","children":[{"level":3,"title":"语义搜索","slug":"语义搜索","link":"#语义搜索","children":[]}]}],"readingTime":{"minutes":0.71,"words":213},"filePathRelative":"posts/研究生组会纪录/第十周.md","excerpt":"\\n<h2>token的限制</h2>\\n<p>普通使用者的误区：认为GPT的token可以分多次对话使用，可以记住我们的历史对话，但是实际上这些数据都存在内存或者数据库，对话时实际是将近几次对话通过prompt拼接在一起，所以token的限制依然存在，当对话数据超过了token的限制，历史就会丢失。</p>\\n<h2>token过大，响应变慢</h2>\\n<h2>创新性的东西</h2>\\n<h3>语义搜索</h3>\\n<p>特定领域的文档转化为向量，存在向量数据库，用户输入问题时，将问题转化成向量，在上下文搜索，找到最相关的文档，再生成回答。</p>\\n<h4>记忆搜索</h4>\\n<p>将提问的向量和以前的向量匹配，找到相近的向量再生成prompt，提高回答质量</p>","autoDesc":true}');export{l as comp,c as data};
